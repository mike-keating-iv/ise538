{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM 538-001: Practical Machine Learning for Enginering Analystics (Spring 2025)  \n",
    "Instructor: Fred Livingston (fjliving@ncsu.edu) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")\n",
    "chicago_taxi_dataset = pd.read_csv(\"chicago_taxi_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_taxi_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data=chicago_taxi_dataset, y=\"FARE\", x=\"TRIP_MILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = chicago_taxi_dataset[\"TRIP_MILES\"]\n",
    "y = chicago_taxi_dataset[\"FARE\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, \n",
    "                         shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "\n",
    "class LinearRegression: \n",
    "    def __init__(self): \n",
    "        self.parameters = {} \n",
    "\n",
    "    def forward_propagation(self, train_input): \n",
    "        w = self.parameters['w'] \n",
    "        b = self.parameters['b'] \n",
    "        predictions = np.multiply(w, train_input) + b \n",
    "        return predictions \n",
    "\n",
    "    def cost_function(self, predictions, train_output): \n",
    "        cost = np.mean((train_output - predictions) ** 2) \n",
    "        return cost \n",
    "\n",
    "    def backward_propagation(self, train_input, train_output, predictions): \n",
    "        derivatives = {} \n",
    "        df = (predictions-train_output) \n",
    "        # dw= 2/n * mean of (predictions-actual) * input \n",
    "        dw = 2 * np.mean(np.multiply(train_input, df)) \n",
    "        # db = 2/n * mean of (predictions-actual) \n",
    "        db = 2 * np.mean(df) \n",
    "        derivatives['dw'] = dw \n",
    "        derivatives['db'] = db \n",
    "        return derivatives \n",
    "\n",
    "    def update_parameters(self, derivatives, learning_rate): \n",
    "        self.parameters['w'] = self.parameters['w'] - learning_rate * derivatives['dw'] \n",
    "        self.parameters['b'] = self.parameters['b'] - learning_rate * derivatives['db'] \n",
    "\n",
    "    def train(self, train_input, train_output, learning_rate, iters): \n",
    "        # Initialize random parameters \n",
    "        self.parameters['w'] = np.random.uniform(0, 1) * -1\n",
    "        self.parameters['b'] = np.random.uniform(0, 1) * -1\n",
    "\n",
    "        # Initialize loss \n",
    "        self.loss = [] \n",
    "\n",
    "        # Initialize figure and axis for animation \n",
    "        fig, ax = plt.subplots() \n",
    "        x_vals = np.linspace(min(train_input), max(train_input), 100) \n",
    "        line, = ax.plot(x_vals, self.parameters['w'] * x_vals +\n",
    "                        self.parameters['b'], color='red', label='Regression Line') \n",
    "        ax.scatter(train_input, train_output, marker='o', \n",
    "                color='green', label='Training Data') \n",
    "\n",
    "        # Set y-axis limits to exclude negative values \n",
    "        ax.set_ylim(0, max(train_output) + 1) \n",
    "\n",
    "        def update(frame): \n",
    "            # Forward propagation \n",
    "            predictions = self.forward_propagation(train_input) \n",
    "\n",
    "            # Cost function \n",
    "            cost = self.cost_function(predictions, train_output) \n",
    "\n",
    "            # Back propagation \n",
    "            derivatives = self.backward_propagation( \n",
    "                train_input, train_output, predictions) \n",
    "\n",
    "            # Update parameters \n",
    "            self.update_parameters(derivatives, learning_rate) \n",
    "\n",
    "            # Update the regression line \n",
    "            line.set_ydata(self.parameters['w'] \n",
    "                        * x_vals + self.parameters['b']) \n",
    "\n",
    "            # Append loss and print \n",
    "            self.loss.append(cost) \n",
    "            print(\"Iteration = {}, Loss = {}, w = {}, b = {}\".format(frame + 1, cost, self.parameters['w'], self.parameters['b'])) \n",
    "           \n",
    "            return line, \n",
    "        # Create animation \n",
    "        ani = FuncAnimation(fig, update, frames=iters, interval=200, blit=True) \n",
    "\n",
    "        # Save the animation as a video file (e.g., MP4) \n",
    "        ani.save('linear_regression_A.gif', writer='ffmpeg') \n",
    "\n",
    "        plt.xlabel('Input') \n",
    "        plt.ylabel('Output') \n",
    "        plt.title('Linear Regression') \n",
    "        plt.legend() \n",
    "        plt.show() \n",
    "\n",
    "        return self.parameters, self.loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "linear_reg = LinearRegression()\n",
    "parameters, loss = linear_reg.train(X_train, y_train, 0.001, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try adjusting the learning rate and number of iterations to see how it affects the loss and the regression line\n",
    "# Try adjusting the ecpochs to see how it affects the loss and the regression line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
