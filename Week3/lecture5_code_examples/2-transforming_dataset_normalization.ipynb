{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM 538-001: Practical Machine Learning for Enginering Analystics (Spring 2025)  \n",
    "Instructor: Fred Livingston (fjliving@ncsu.edu)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data[:, 2:], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, \n",
    "                         shuffle=True, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_temp, y_temp, test_size=0.2,\n",
    "                         shuffle=True, random_state=123, stratify=y_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the case of the Iris dataset, all dimensions were measured in centimeters, hence \"scaling\" features would not be necessary in the context of *k*NN -- unless we want to weight features differently.\n",
    "- Whether or not to scale features depends on the problem at hand and requires your judgement.\n",
    "- However, there are several algorithms (especially gradient-descent, etc., which we will cover later in this course), which work much better (are more robust, numerically stable, and converge faster) if the data is centered and has a smaller range.\n",
    "- There are many different ways for scaling features; here, we only cover to of the most common \"normalization\" schemes: min-max scaling and z-score standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization -- Min-max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min-max scaling squashes the features into a [0, 1] range, which can be achieved via the following equation for a single input $i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{[i]}_{\\text{norm}} = \\frac{x^{[i]} - x_{\\text{min}} }{ x_{\\text{max}} - x_{\\text{min}} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Z-score standardization is a useful standardization scheme if we are working with certain optimization methods (e.g., gradient descent, later in this course). \n",
    "- After standardizing a feature, it will have the properties of a standard normal distribution, that is, unit variance and zero mean ($N(\\mu=0, \\sigma^2=1)$); however, this does not transform a feature from not following a normal distribution to a normal distributed one.\n",
    "- The formula for standardizing a feature is shown below, for a single data point $x^{[i]}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{[i]}_{\\text{std}} = \\frac{x^{[i]} - \\mu_x }{ \\sigma_{x} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A concept that is very important though is how we use the estimated normalization parameters (e.g., mean and standard deviation in z-score standardization).\n",
    "- In particular, it is important that we re-use the parameters estimated from the training set to transfrom validation and test sets -- re-estimating the parameters is a common \"beginner-mistake\" which is why we discuss it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = X_train.mean(axis=0), X_train.std(axis=0)\n",
    "\n",
    "X_train_std = (X_train - mu) / sigma\n",
    "X_valid_std = (X_valid - mu) / sigma\n",
    "X_test_std = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The transformer API in scikit-learn is very similar to the estimator API; the main difference is that transformers are typically \"unsupervised,\" meaning, they don't make use of class labels or target values.\n",
    "\n",
    "<img src=\"images/transformer-api.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "- Typical examples of transformers in scikit-learn are the `MinMaxScaler` and the `StandardScaler`, which can be used to perform min-max scaling and z-score standardization as discussed earlier.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_valid_std = scaler.transform(X_valid)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train_std, y_train)\n",
    "y_pred = knn_model.predict(X_test_std)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %.2f%%' % (knn_model.score(X_test_std, y_test)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
